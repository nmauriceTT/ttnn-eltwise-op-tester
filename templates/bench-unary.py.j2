import ttnn
from operations import UNARY_OPERATIONS, get_operation_variant_by_name

ITERATIONS = {{ ITERATIONS }}
DTYPE = {{ DTYPE }}


device = ttnn.open_device(device_id=0)

shard_shape = [512, 512]
grid = ttnn.CoreGrid(x=8, y=8)

shape = (1, 1, grid.y * grid.x * shard_shape[0], shard_shape[1])
mem_config = ttnn.create_sharded_memory_config(
    shape,
    core_grid=grid,
    strategy=ttnn.ShardStrategy.HEIGHT,
    orientation=ttnn.ShardOrientation.ROW_MAJOR,
)

ttnn_dtype = getattr(ttnn, DTYPE)

input_tensor = ttnn.full(shape=shape, fill_value=1.0, dtype=ttnn_dtype, device=device, layout=ttnn.TILE_LAYOUT, memory_config=mem_config)

ttnn_operation = get_operation_variant_by_name(UNARY_OPERATIONS, {{ IMPLEMENTATION_NAME }})

for i in range(ITERATIONS):
    y = ttnn_operation(input_tensor, output_tensor=None)
    ttnn.deallocate(y)

ttnn.synchronize_device(device)
ttnn.close_device(device)